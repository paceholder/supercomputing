<?xml version="1.0" encoding="UTF-8"?>
<Experiment xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.lrr.in.tum.de/Periscope" xsi:schemaLocation="http://www.lrr.in.tum.de/Periscope psc_properties.xsd ">

  <date>2013-02-07</date>
  <time>21:54:01</time>
  <numProcs>64</numProcs>
  <numThreads>1</numThreads>
  <dir>/home/hpc/h039u/h039uan/supercomputing/A2.4/code</dir>
  <sir>./gccg.sir</sir>

  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="49" thread="0"/>
		<execObj process="48" thread="0"/>
		<execObj process="17" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="16" thread="0"/>
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
	</context>
	<severity>25.244</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="45" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
		<execObj process="48" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="20" thread="0"/>
		<execObj process="17" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="16" thread="0"/>
	</context>
	<severity>49.3137</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="57" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="9" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="7" thread="0"/>
		<execObj process="8" thread="0"/>
	</context>
	<severity>60.6775</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="33" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="25" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>34.9876</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="33" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="30" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="28" thread="0"/>
	</context>
	<severity>38.6664</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="51" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="53" thread="0"/>
		<execObj process="12" thread="0"/>
		<execObj process="0" thread="0"/>
	</context>
	<severity>55.3346</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="23" thread="0"/>
		<execObj process="24" thread="0"/>
		<execObj process="38" thread="0"/>
		<execObj process="22" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
	</context>
	<severity>31.1205</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="10" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="1" thread="0"/>
		<execObj process="20" thread="0"/>
		<execObj process="17" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="16" thread="0"/>
	</context>
	<severity>47.0561</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="4" thread="0"/>
		<execObj process="9" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="7" thread="0"/>
		<execObj process="8" thread="0"/>
	</context>
	<severity>50.1306</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="50" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
	</context>
	<severity>22.3046</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="29" thread="0"/>
		<execObj process="28" thread="0"/>
	</context>
	<severity>36.5425</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="23" thread="0"/>
		<execObj process="24" thread="0"/>
		<execObj process="22" thread="0"/>
		<execObj process="12" thread="0"/>
		<execObj process="0" thread="0"/>
	</context>
	<severity>43.7729</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="33" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>32.2229</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="38" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="24" thread="0"/>
	</context>
	<severity>44.5032</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="1" thread="0"/>
		<execObj process="10" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="0" thread="0"/>
		<execObj process="9" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>15.9306</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="20" thread="0"/>
		<execObj process="28" thread="0"/>
		<execObj process="24" thread="0"/>
		<execObj process="17" thread="0"/>
		<execObj process="21" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="25" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="22" thread="0"/>
		<execObj process="30" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="16" thread="0"/>
		<execObj process="36" thread="0"/>
		<execObj process="40" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="33" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="38" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="44" thread="0"/>
		<execObj process="56" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="48" thread="0"/>
		<execObj process="60" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="53" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="58" thread="0"/>
		<execObj process="54" thread="0"/>
		<execObj process="50" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="60" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="58" thread="0"/>
		<execObj process="0" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="12" thread="0"/>
		<execObj process="8" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="9" thread="0"/>
		<execObj process="1" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="13" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="10" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="7" thread="0"/>
		<execObj process="15" thread="0"/>
		<execObj process="7" thread="0"/>
		<execObj process="8" thread="0"/>
	</context>
	<severity>12.8898</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="38" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
	</context>
	<severity>28.2745</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="13" thread="0"/>
		<execObj process="50" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="52" thread="0"/>
	</context>
	<severity>22.6974</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="53" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="12" thread="0"/>
	</context>
	<severity>20.0756</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="54" thread="0"/>
		<execObj process="10" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="1" thread="0"/>
	</context>
	<severity>57.8985</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="26" thread="0"/>
		<execObj process="25" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>41.0665</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="42" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="21" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="20" thread="0"/>
	</context>
	<severity>27.6741</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="57" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>16.0646</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="50" thread="0"/>
		<execObj process="13" thread="0"/>
	</context>
	<severity>52.6099</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="30" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="28" thread="0"/>
	</context>
	<severity>36.3268</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="41" thread="0"/>
		<execObj process="21" thread="0"/>
	</context>
	<severity>47.2036</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="42" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="48" thread="0"/>
	</context>
	<severity>25.2405</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="13" thread="0"/>
	</context>
	<severity>42.1673</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>2878750</CallTime>
		<LateTime>2283449</LateTime>
		<PhaseTime>5415211</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="61" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="60" thread="0"/>
	</context>
	<severity>11.964</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="21" thread="0"/>
	</context>
	<severity>45.9606</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>2575142</CallTime>
		<LateTime>2488860</LateTime>
		<PhaseTime>5415199</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
	</context>
	<severity>50.7797</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="25" thread="0"/>
	</context>
	<severity>39.4902</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="22" thread="0"/>
	</context>
	<severity>45.9436</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>2487935</CallTime>
		<PhaseTime>5415198</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="61" thread="0"/>
		<execObj process="58" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="60" thread="0"/>
	</context>
	<severity>63.7829</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-179" >
	<name>Excessive MPI time in receive due to late sender</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="63" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="60" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="53" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="58" thread="0"/>
		<execObj process="54" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>9.65036</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-179" >
	<name>Excessive MPI time in receive due to late sender</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="51" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="50" thread="0"/>
		<execObj process="48" thread="0"/>
	</context>
	<severity>6.55406</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="31" thread="0"/>
		<execObj process="30" thread="0"/>
	</context>
	<severity>34.8037</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="53" thread="0"/>
	</context>
	<severity>19.8235</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1073481</CallTime>
		<LateTime>1658858</LateTime>
		<PhaseTime>5415193</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="54" thread="0"/>
	</context>
	<severity>18.1527</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>983004</CallTime>
		<PhaseTime>5415183</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="58" thread="0"/>
	</context>
	<severity>13.9537</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>755622</CallTime>
		<LateTime>1349203</LateTime>
		<PhaseTime>5415190</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="54" thread="0"/>
	</context>
	<severity>18.1527</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>983004</CallTime>
		<LateTime>1570902</LateTime>
		<PhaseTime>5415183</PhaseTime>
	</addInfo>
  </property>
</Experiment>
