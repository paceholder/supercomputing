<?xml version="1.0" encoding="UTF-8"?>
<Experiment xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.lrr.in.tum.de/Periscope" xsi:schemaLocation="http://www.lrr.in.tum.de/Periscope psc_properties.xsd ">

  <date>2013-02-07</date>
  <time>22:52:16</time>
  <numProcs>64</numProcs>
  <numThreads>1</numThreads>
  <dir>/home/hpc/h039u/h039uan/supercomputing/A2.4/code</dir>
  <sir>./gccg.sir</sir>

  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="38" thread="0"/>
		<execObj process="21" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="20" thread="0"/>
	</context>
	<severity>50.3498</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="7" thread="0"/>
		<execObj process="0" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="60" thread="0"/>
	</context>
	<severity>13.3809</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="13" thread="0"/>
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="50" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="16" thread="0"/>
	</context>
	<severity>55.6618</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="61" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="60" thread="0"/>
	</context>
	<severity>12.6269</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="1" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="60" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="0" thread="0"/>
	</context>
	<severity>72.0506</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="24" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="28" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="33" thread="0"/>
		<execObj process="32" thread="0"/>
	</context>
	<severity>37.6287</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="45" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
		<execObj process="12" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="52" thread="0"/>
	</context>
	<severity>24.4789</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="1" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="0" thread="0"/>
	</context>
	<severity>72.5978</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="30" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="21" thread="0"/>
		<execObj process="22" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>34.9733</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="33" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="28" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="24" thread="0"/>
	</context>
	<severity>45.0138</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="41" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="48" thread="0"/>
	</context>
	<severity>29.7119</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="21" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="20" thread="0"/>
	</context>
	<severity>37.4692</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="9" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>17.9089</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="58" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="8" thread="0"/>
	</context>
	<severity>67.6759</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="17" thread="0"/>
		<execObj process="16" thread="0"/>
	</context>
	<severity>42.4081</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="16" thread="0"/>
		<execObj process="28" thread="0"/>
		<execObj process="24" thread="0"/>
		<execObj process="21" thread="0"/>
		<execObj process="17" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="25" thread="0"/>
		<execObj process="22" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="30" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="20" thread="0"/>
		<execObj process="36" thread="0"/>
		<execObj process="44" thread="0"/>
		<execObj process="40" thread="0"/>
		<execObj process="33" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="38" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="32" thread="0"/>
		<execObj process="8" thread="0"/>
		<execObj process="12" thread="0"/>
		<execObj process="1" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="9" thread="0"/>
		<execObj process="13" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="10" thread="0"/>
		<execObj process="14" thread="0"/>
		<execObj process="6" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="7" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="15" thread="0"/>
		<execObj process="4" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="48" thread="0"/>
		<execObj process="56" thread="0"/>
		<execObj process="61" thread="0"/>
		<execObj process="53" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="57" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="62" thread="0"/>
		<execObj process="54" thread="0"/>
		<execObj process="50" thread="0"/>
		<execObj process="58" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="63" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="59" thread="0"/>
		<execObj process="60" thread="0"/>
	</context>
	<severity>10.8934</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="51" thread="0"/>
		<execObj process="52" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="46" thread="0"/>
		<execObj process="12" thread="0"/>
	</context>
	<severity>58.5907</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="22" thread="0"/>
		<execObj process="34" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="33" thread="0"/>
		<execObj process="32" thread="0"/>
	</context>
	<severity>33.776</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="52" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="51" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="28" thread="0"/>
	</context>
	<severity>23.8474</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="24" thread="0"/>
		<execObj process="48" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>30.5422</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="54" thread="0"/>
		<execObj process="53" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="30" thread="0"/>
		<execObj process="45" thread="0"/>
		<execObj process="43" thread="0"/>
		<execObj process="44" thread="0"/>
	</context>
	<severity>21.5424</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="57" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>16.3638</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="8" thread="0"/>
	</context>
	<severity>67.271</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1586346</CallTime>
		<LateTime>2120013</LateTime>
		<PhaseTime>2358142</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="50" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="27" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
	</context>
	<severity>26.6869</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="38" thread="0"/>
		<execObj process="19" thread="0"/>
		<execObj process="20" thread="0"/>
	</context>
	<severity>32.22</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="12" thread="0"/>
	</context>
	<severity>58.702</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1384291</CallTime>
		<LateTime>1915566</LateTime>
		<PhaseTime>2358165</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="50" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="42" thread="0"/>
		<execObj process="13" thread="0"/>
		<execObj process="16" thread="0"/>
	</context>
	<severity>27.1103</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="4" thread="0"/>
		<execObj process="1" thread="0"/>
		<execObj process="5" thread="0"/>
		<execObj process="2" thread="0"/>
		<execObj process="3" thread="0"/>
		<execObj process="0" thread="0"/>
	</context>
	<severity>9.36352</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="48" thread="0"/>
		<execObj process="41" thread="0"/>
		<execObj process="39" thread="0"/>
		<execObj process="40" thread="0"/>
		<execObj process="49" thread="0"/>
		<execObj process="18" thread="0"/>
		<execObj process="17" thread="0"/>
	</context>
	<severity>53.4034</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="22" thread="0"/>
		<execObj process="30" thread="0"/>
		<execObj process="23" thread="0"/>
		<execObj process="31" thread="0"/>
		<execObj process="29" thread="0"/>
		<execObj process="37" thread="0"/>
		<execObj process="35" thread="0"/>
		<execObj process="36" thread="0"/>
	</context>
	<severity>47.913</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="25" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="26" thread="0"/>
		<execObj process="25" thread="0"/>
	</context>
	<severity>41.7042</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="9" thread="0"/>
		<execObj process="55" thread="0"/>
		<execObj process="56" thread="0"/>
	</context>
	<severity>64.6689</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="58" thread="0"/>
		<execObj process="8" thread="0"/>
	</context>
	<severity>15.4993</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="38" thread="0"/>
		<execObj process="25" thread="0"/>
	</context>
	<severity>28.8392</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="10" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="54" thread="0"/>
		<execObj process="53" thread="0"/>
	</context>
	<severity>21.4994</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="17" thread="0"/>
	</context>
	<severity>28.2295</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>665694</CallTime>
		<PhaseTime>2358148</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="9" thread="0"/>
	</context>
	<severity>65.036</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1533647</CallTime>
		<LateTime>2067330</LateTime>
		<PhaseTime>2358150</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="10" thread="0"/>
		<execObj process="11" thread="0"/>
		<execObj process="54" thread="0"/>
		<execObj process="53" thread="0"/>
	</context>
	<severity>61.7531</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="13" thread="0"/>
	</context>
	<severity>56.7922</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1339254</CallTime>
		<LateTime>1872612</LateTime>
		<PhaseTime>2358166</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="18" thread="0"/>
	</context>
	<severity>40.2122</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1249413</CallTime>
		<LateTime>948263</LateTime>
		<PhaseTime>2358148</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="55" thread="0"/>
		<execObj process="47" thread="0"/>
		<execObj process="46" thread="0"/>
	</context>
	<severity>19.2676</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="63" thread="0"/>
		<execObj process="62" thread="0"/>
	</context>
	<severity>10.6196</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-172" >
	<name>Excessive MPI communication time in MPI_RECV</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="34" thread="0"/>
	</context>
	<severity>46.7252</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1101849</CallTime>
		<PhaseTime>2358149</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="58" thread="0"/>
	</context>
	<severity>14.5048</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>360140</CallTime>
		<LateTime>342046</LateTime>
		<PhaseTime>2358154</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="10" thread="0"/>
	</context>
	<severity>62.7941</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1480777</CallTime>
		<LateTime>2012686</LateTime>
		<PhaseTime>2358148</PhaseTime>
	</addInfo>
  </property>
  <property cluster="true" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="15" thread="0"/>
		<execObj process="14" thread="0"/>
	</context>
	<severity>54.5124</severity>
	<confidence>1</confidence>
	<addInfo>
	</addInfo>
  </property>
  <property cluster="false" ID="7-172" >
	<name>Excessive MPI communication time in MPI_ALLREDUCE</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="7" thread="0"/>
	</context>
	<severity>69.3924</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1636384</CallTime>
		<PhaseTime>2358161</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="7" thread="0"/>
	</context>
	<severity>69.3924</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1636384</CallTime>
		<LateTime>2168778</LateTime>
		<PhaseTime>2358161</PhaseTime>
	</addInfo>
  </property>
  <property cluster="false" ID="7-187" >
	<name>Excessive MPI time due to late process in allreduce</name>
	<context FileID="9" FileName="compute_solution.c" RFL="17" Config="64x1" Region="MPI_CALL" RegionId="9-17" >
		<execObj process="11" thread="0"/>
	</context>
	<severity>60.6045</severity>
	<confidence>1</confidence>
	<addInfo>
		<CallTime>1429142</CallTime>
		<LateTime>1964282</LateTime>
		<PhaseTime>2358145</PhaseTime>
	</addInfo>
  </property>
</Experiment>
